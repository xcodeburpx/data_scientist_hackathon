{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import numpy as np \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import trange, tqdm\n",
    "import pickle\n",
    "\n",
    "from hackathon.utils.utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (5, 5)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kinshiryuu-burp/anaconda3/envs/nitinol/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import ElasticNet, Ridge\n",
    "from sklearn.linear_model import HuberRegressor, RANSACRegressor, SGDRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.regularizers import *\n",
    "from keras.optimizers import *\n",
    "from keras.metrics import *\n",
    "from keras.activations import *\n",
    "from keras.losses import *\n",
    "from keras.objectives import *\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hackathon.utils.utils import *\n",
    "from hackathon.utils.draw_utils import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load prepared data\n",
    "test_data = parse_data(\"../data/test_data.csv\")\n",
    "train_data = parse_data(\"../data/train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55375, 81)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NPWD2372</th>\n",
       "      <th>NPWD2401</th>\n",
       "      <th>NPWD2402</th>\n",
       "      <th>NPWD2451</th>\n",
       "      <th>NPWD2471</th>\n",
       "      <th>NPWD2472</th>\n",
       "      <th>NPWD2481</th>\n",
       "      <th>NPWD2482</th>\n",
       "      <th>NPWD2491</th>\n",
       "      <th>NPWD2501</th>\n",
       "      <th>...</th>\n",
       "      <th>D3POCM</th>\n",
       "      <th>D2PLND</th>\n",
       "      <th>D5PPHB</th>\n",
       "      <th>D7PLTS</th>\n",
       "      <th>D8PLTP</th>\n",
       "      <th>SPOT</th>\n",
       "      <th>D9PSPO</th>\n",
       "      <th>usbx</th>\n",
       "      <th>usby</th>\n",
       "      <th>usbz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ut_ms</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-11 03:00:00</th>\n",
       "      <td>0.153997</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.175747</td>\n",
       "      <td>0.413997</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.250222</td>\n",
       "      <td>0.005270</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.885074</td>\n",
       "      <td>-0.015705</td>\n",
       "      <td>-0.465185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 04:00:00</th>\n",
       "      <td>0.182451</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.175296</td>\n",
       "      <td>0.718407</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>0.293467</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.229725</td>\n",
       "      <td>-0.297169</td>\n",
       "      <td>0.926778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 05:00:00</th>\n",
       "      <td>0.068337</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.175418</td>\n",
       "      <td>0.605100</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.109192</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.682524</td>\n",
       "      <td>0.585007</td>\n",
       "      <td>-0.438096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 06:00:00</th>\n",
       "      <td>0.067819</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.175529</td>\n",
       "      <td>0.916710</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>0.153566</td>\n",
       "      <td>0.005179</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.693310</td>\n",
       "      <td>0.493665</td>\n",
       "      <td>-0.524992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 07:00:00</th>\n",
       "      <td>0.091699</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.175465</td>\n",
       "      <td>0.238846</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.154937</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.343933</td>\n",
       "      <td>0.397570</td>\n",
       "      <td>-0.850675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 08:00:00</th>\n",
       "      <td>0.103793</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.175529</td>\n",
       "      <td>0.509307</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.176760</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.757616</td>\n",
       "      <td>0.154589</td>\n",
       "      <td>0.634129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 09:00:00</th>\n",
       "      <td>0.187734</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.175230</td>\n",
       "      <td>0.345856</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>0.300233</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.224307</td>\n",
       "      <td>-0.950424</td>\n",
       "      <td>0.215360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 10:00:00</th>\n",
       "      <td>0.139870</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.175762</td>\n",
       "      <td>0.763595</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.191653</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.530428</td>\n",
       "      <td>0.724253</td>\n",
       "      <td>-0.440571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 11:00:00</th>\n",
       "      <td>0.180813</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.175089</td>\n",
       "      <td>1.321200</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.315071</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.520810</td>\n",
       "      <td>0.113966</td>\n",
       "      <td>-0.846031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 12:00:00</th>\n",
       "      <td>0.054422</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.175389</td>\n",
       "      <td>1.021229</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.108283</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.131807</td>\n",
       "      <td>0.054685</td>\n",
       "      <td>-0.989766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 13:00:00</th>\n",
       "      <td>0.068415</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.175277</td>\n",
       "      <td>0.759537</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.132422</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.690428</td>\n",
       "      <td>0.509820</td>\n",
       "      <td>-0.513219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 14:00:00</th>\n",
       "      <td>0.107229</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.175482</td>\n",
       "      <td>0.734023</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.184174</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.690109</td>\n",
       "      <td>0.514692</td>\n",
       "      <td>-0.508764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 15:00:00</th>\n",
       "      <td>0.114952</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.175277</td>\n",
       "      <td>0.257654</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.162479</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.690109</td>\n",
       "      <td>0.514692</td>\n",
       "      <td>-0.508764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 16:00:00</th>\n",
       "      <td>0.126895</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.176881</td>\n",
       "      <td>0.510851</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.191965</td>\n",
       "      <td>0.005401</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.689335</td>\n",
       "      <td>0.519060</td>\n",
       "      <td>-0.505365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 17:00:00</th>\n",
       "      <td>0.148080</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.175747</td>\n",
       "      <td>0.259542</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.162975</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.985110</td>\n",
       "      <td>-0.161523</td>\n",
       "      <td>0.058896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 18:00:00</th>\n",
       "      <td>0.222082</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>0.175389</td>\n",
       "      <td>0.526600</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.301563</td>\n",
       "      <td>0.005206</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.985110</td>\n",
       "      <td>-0.161523</td>\n",
       "      <td>0.058896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 19:00:00</th>\n",
       "      <td>0.098322</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.176264</td>\n",
       "      <td>0.456733</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.044339</td>\n",
       "      <td>0.005351</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.740896</td>\n",
       "      <td>0.657717</td>\n",
       "      <td>-0.135946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 20:00:00</th>\n",
       "      <td>0.094006</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.174970</td>\n",
       "      <td>0.314447</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.138640</td>\n",
       "      <td>0.005223</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687305</td>\n",
       "      <td>0.527384</td>\n",
       "      <td>-0.499477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 21:00:00</th>\n",
       "      <td>0.114830</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.175935</td>\n",
       "      <td>0.404463</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.124385</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.686714</td>\n",
       "      <td>0.532478</td>\n",
       "      <td>-0.494864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 22:00:00</th>\n",
       "      <td>0.136468</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.174504</td>\n",
       "      <td>0.362581</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>0.157216</td>\n",
       "      <td>0.005108</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685437</td>\n",
       "      <td>0.536481</td>\n",
       "      <td>-0.492305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-11 23:00:00</th>\n",
       "      <td>0.131199</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.173960</td>\n",
       "      <td>0.472506</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.162316</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685437</td>\n",
       "      <td>0.536481</td>\n",
       "      <td>-0.492305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-12 00:00:00</th>\n",
       "      <td>0.146903</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.175389</td>\n",
       "      <td>0.295220</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.180173</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.669669</td>\n",
       "      <td>-0.492722</td>\n",
       "      <td>-0.555669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-12 01:00:00</th>\n",
       "      <td>0.200859</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.175277</td>\n",
       "      <td>0.532107</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.262145</td>\n",
       "      <td>0.005198</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.669669</td>\n",
       "      <td>-0.492722</td>\n",
       "      <td>-0.555669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-12 02:00:00</th>\n",
       "      <td>0.153043</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.175576</td>\n",
       "      <td>0.334543</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.236772</td>\n",
       "      <td>0.005241</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.704083</td>\n",
       "      <td>-0.699514</td>\n",
       "      <td>-0.122256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-12 03:00:00</th>\n",
       "      <td>0.068421</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.175465</td>\n",
       "      <td>0.415733</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.082625</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.726133</td>\n",
       "      <td>0.223954</td>\n",
       "      <td>0.650058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-12 04:00:00</th>\n",
       "      <td>0.080820</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.175203</td>\n",
       "      <td>0.237566</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>0.005197</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.682456</td>\n",
       "      <td>0.551079</td>\n",
       "      <td>-0.480173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-12 05:00:00</th>\n",
       "      <td>0.081844</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>0.513040</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681244</td>\n",
       "      <td>0.555850</td>\n",
       "      <td>-0.476379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-12 06:00:00</th>\n",
       "      <td>0.107229</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.175855</td>\n",
       "      <td>0.256917</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.191603</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681244</td>\n",
       "      <td>0.555850</td>\n",
       "      <td>-0.476379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-12 07:00:00</th>\n",
       "      <td>0.164525</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.175183</td>\n",
       "      <td>0.511966</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.258488</td>\n",
       "      <td>0.005189</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.254060</td>\n",
       "      <td>-0.847400</td>\n",
       "      <td>0.466225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-12 08:00:00</th>\n",
       "      <td>0.196250</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.175156</td>\n",
       "      <td>0.477366</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.308590</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.867239</td>\n",
       "      <td>0.249444</td>\n",
       "      <td>0.430900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30 17:00:00</th>\n",
       "      <td>0.154245</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.174854</td>\n",
       "      <td>0.521866</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.200769</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.989760</td>\n",
       "      <td>-0.098915</td>\n",
       "      <td>-0.102910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30 18:00:00</th>\n",
       "      <td>0.080845</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.175389</td>\n",
       "      <td>0.411753</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.032638</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.827998</td>\n",
       "      <td>-0.328984</td>\n",
       "      <td>-0.454080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30 19:00:00</th>\n",
       "      <td>0.094614</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.174948</td>\n",
       "      <td>0.356401</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.116687</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.526083</td>\n",
       "      <td>-0.633256</td>\n",
       "      <td>0.567648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30 20:00:00</th>\n",
       "      <td>0.113804</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.174737</td>\n",
       "      <td>0.525846</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.153516</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.516009</td>\n",
       "      <td>-0.642768</td>\n",
       "      <td>0.566201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30 21:00:00</th>\n",
       "      <td>0.121423</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.176782</td>\n",
       "      <td>0.288537</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.178714</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.505809</td>\n",
       "      <td>-0.652130</td>\n",
       "      <td>0.564698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30 22:00:00</th>\n",
       "      <td>0.133253</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>0.175482</td>\n",
       "      <td>0.499653</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.168664</td>\n",
       "      <td>0.005206</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.505809</td>\n",
       "      <td>-0.652130</td>\n",
       "      <td>0.564698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30 23:00:00</th>\n",
       "      <td>0.207405</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.175935</td>\n",
       "      <td>0.456876</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.284815</td>\n",
       "      <td>0.005342</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.447202</td>\n",
       "      <td>-0.865417</td>\n",
       "      <td>-0.225974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 00:00:00</th>\n",
       "      <td>0.212269</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.175482</td>\n",
       "      <td>0.390973</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.274715</td>\n",
       "      <td>0.005170</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.870309</td>\n",
       "      <td>-0.491546</td>\n",
       "      <td>0.030735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 01:00:00</th>\n",
       "      <td>0.107903</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.175277</td>\n",
       "      <td>0.492862</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.177813</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.179477</td>\n",
       "      <td>-0.213799</td>\n",
       "      <td>0.960249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 02:00:00</th>\n",
       "      <td>0.179497</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.175669</td>\n",
       "      <td>0.237167</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.255745</td>\n",
       "      <td>0.005170</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.814450</td>\n",
       "      <td>0.561373</td>\n",
       "      <td>0.146735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 03:00:00</th>\n",
       "      <td>0.094964</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>0.297525</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.136090</td>\n",
       "      <td>0.005270</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.872542</td>\n",
       "      <td>-0.430147</td>\n",
       "      <td>0.231611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 04:00:00</th>\n",
       "      <td>0.153067</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.175296</td>\n",
       "      <td>0.430856</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.282714</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.810199</td>\n",
       "      <td>-0.478498</td>\n",
       "      <td>0.338553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 05:00:00</th>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.175606</td>\n",
       "      <td>0.551998</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.193292</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.909400</td>\n",
       "      <td>0.386019</td>\n",
       "      <td>-0.154857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 06:00:00</th>\n",
       "      <td>0.136761</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.175529</td>\n",
       "      <td>0.789388</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.225703</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.964785</td>\n",
       "      <td>-0.214806</td>\n",
       "      <td>-0.151819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 07:00:00</th>\n",
       "      <td>0.091378</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.174759</td>\n",
       "      <td>1.125684</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>0.166306</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.440630</td>\n",
       "      <td>0.417733</td>\n",
       "      <td>0.794572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 08:00:00</th>\n",
       "      <td>0.028369</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.175063</td>\n",
       "      <td>0.982127</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.115826</td>\n",
       "      <td>0.005179</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437760</td>\n",
       "      <td>0.730833</td>\n",
       "      <td>-0.523687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 09:00:00</th>\n",
       "      <td>0.061677</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.175371</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>0.147442</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.356817</td>\n",
       "      <td>-0.629448</td>\n",
       "      <td>0.690273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 10:00:00</th>\n",
       "      <td>0.034764</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.175343</td>\n",
       "      <td>0.488802</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.153874</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.187903</td>\n",
       "      <td>-0.320970</td>\n",
       "      <td>-0.928262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 11:00:00</th>\n",
       "      <td>0.041713</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.175371</td>\n",
       "      <td>0.856548</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.155158</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.952969</td>\n",
       "      <td>-0.225019</td>\n",
       "      <td>0.203019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 12:00:00</th>\n",
       "      <td>0.061076</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.175809</td>\n",
       "      <td>0.694797</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>0.153709</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.776475</td>\n",
       "      <td>-0.483831</td>\n",
       "      <td>0.403724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 13:00:00</th>\n",
       "      <td>0.147793</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.175559</td>\n",
       "      <td>1.011530</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.277490</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.138345</td>\n",
       "      <td>-0.916342</td>\n",
       "      <td>0.375738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 14:00:00</th>\n",
       "      <td>0.126588</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.175855</td>\n",
       "      <td>0.733278</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.176978</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.356568</td>\n",
       "      <td>-0.725765</td>\n",
       "      <td>0.588324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 15:00:00</th>\n",
       "      <td>0.055026</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.175230</td>\n",
       "      <td>0.817938</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.147366</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.581641</td>\n",
       "      <td>-0.287230</td>\n",
       "      <td>-0.761047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 16:00:00</th>\n",
       "      <td>0.106658</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.174970</td>\n",
       "      <td>0.401274</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.001895</td>\n",
       "      <td>0.191825</td>\n",
       "      <td>0.005241</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.581641</td>\n",
       "      <td>-0.287230</td>\n",
       "      <td>-0.761047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 17:00:00</th>\n",
       "      <td>0.114446</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.175794</td>\n",
       "      <td>0.347431</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.177962</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.669814</td>\n",
       "      <td>-0.353815</td>\n",
       "      <td>-0.652812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 18:00:00</th>\n",
       "      <td>0.179299</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.175156</td>\n",
       "      <td>0.468635</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.308536</td>\n",
       "      <td>0.005223</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.808397</td>\n",
       "      <td>-0.501676</td>\n",
       "      <td>0.307921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>0.137878</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>0.394912</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.189179</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.883140</td>\n",
       "      <td>0.177234</td>\n",
       "      <td>-0.434340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>0.156473</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.175296</td>\n",
       "      <td>0.964471</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.259449</td>\n",
       "      <td>0.005179</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.332083</td>\n",
       "      <td>-0.124844</td>\n",
       "      <td>0.934952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>0.101617</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.175230</td>\n",
       "      <td>1.127009</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.147062</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.383805</td>\n",
       "      <td>-0.918458</td>\n",
       "      <td>0.095539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>0.071081</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.175389</td>\n",
       "      <td>0.503558</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.146262</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342380</td>\n",
       "      <td>-0.774606</td>\n",
       "      <td>0.531753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     NPWD2372  NPWD2401  NPWD2402  NPWD2451  NPWD2471  \\\n",
       "ut_ms                                                                   \n",
       "2014-12-11 03:00:00  0.153997  0.001548  0.175747  0.413997  0.000741   \n",
       "2014-12-11 04:00:00  0.182451  0.001518  0.175296  0.718407  0.000736   \n",
       "2014-12-11 05:00:00  0.068337  0.001524  0.175418  0.605100  0.000745   \n",
       "2014-12-11 06:00:00  0.067819  0.001518  0.175529  0.916710  0.000745   \n",
       "2014-12-11 07:00:00  0.091699  0.001513  0.175465  0.238846  0.000739   \n",
       "2014-12-11 08:00:00  0.103793  0.001529  0.175529  0.509307  0.000745   \n",
       "2014-12-11 09:00:00  0.187734  0.001527  0.175230  0.345856  0.000760   \n",
       "2014-12-11 10:00:00  0.139870  0.001534  0.175762  0.763595  0.000743   \n",
       "2014-12-11 11:00:00  0.180813  0.001513  0.175089  1.321200  0.000749   \n",
       "2014-12-11 12:00:00  0.054422  0.001484  0.175389  1.021229  0.000736   \n",
       "2014-12-11 13:00:00  0.068415  0.001524  0.175277  0.759537  0.000749   \n",
       "2014-12-11 14:00:00  0.107229  0.001534  0.175482  0.734023  0.000740   \n",
       "2014-12-11 15:00:00  0.114952  0.001534  0.175277  0.257654  0.000742   \n",
       "2014-12-11 16:00:00  0.126895  0.001557  0.176881  0.510851  0.000772   \n",
       "2014-12-11 17:00:00  0.148080  0.001577  0.175747  0.259542  0.000735   \n",
       "2014-12-11 18:00:00  0.222082  0.001547  0.175389  0.526600  0.000750   \n",
       "2014-12-11 19:00:00  0.098322  0.001587  0.176264  0.456733  0.000767   \n",
       "2014-12-11 20:00:00  0.094006  0.001534  0.174970  0.314447  0.000745   \n",
       "2014-12-11 21:00:00  0.114830  0.001553  0.175935  0.404463  0.000754   \n",
       "2014-12-11 22:00:00  0.136468  0.001490  0.174504  0.362581  0.000735   \n",
       "2014-12-11 23:00:00  0.131199  0.001474  0.173960  0.472506  0.000722   \n",
       "2014-12-12 00:00:00  0.146903  0.001521  0.175389  0.295220  0.000737   \n",
       "2014-12-12 01:00:00  0.200859  0.001516  0.175277  0.532107  0.000737   \n",
       "2014-12-12 02:00:00  0.153043  0.001529  0.175576  0.334543  0.000733   \n",
       "2014-12-12 03:00:00  0.068421  0.001563  0.175465  0.415733  0.000736   \n",
       "2014-12-12 04:00:00  0.080820  0.001529  0.175203  0.237566  0.000735   \n",
       "2014-12-12 05:00:00  0.081844  0.001529  0.175653  0.513040  0.000744   \n",
       "2014-12-12 06:00:00  0.107229  0.001518  0.175855  0.256917  0.000747   \n",
       "2014-12-12 07:00:00  0.164525  0.001511  0.175183  0.511966  0.000742   \n",
       "2014-12-12 08:00:00  0.196250  0.001534  0.175156  0.477366  0.000737   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2014-12-30 17:00:00  0.154245  0.001516  0.174854  0.521866  0.000737   \n",
       "2014-12-30 18:00:00  0.080845  0.001523  0.175389  0.411753  0.000728   \n",
       "2014-12-30 19:00:00  0.094614  0.001484  0.174948  0.356401  0.000739   \n",
       "2014-12-30 20:00:00  0.113804  0.001508  0.174737  0.525846  0.000731   \n",
       "2014-12-30 21:00:00  0.121423  0.001553  0.176782  0.288537  0.000800   \n",
       "2014-12-30 22:00:00  0.133253  0.001503  0.175482  0.499653  0.000738   \n",
       "2014-12-30 23:00:00  0.207405  0.001579  0.175935  0.456876  0.000740   \n",
       "2014-12-31 00:00:00  0.212269  0.001557  0.175482  0.390973  0.000745   \n",
       "2014-12-31 01:00:00  0.107903  0.001548  0.175277  0.492862  0.000735   \n",
       "2014-12-31 02:00:00  0.179497  0.001555  0.175669  0.237167  0.000733   \n",
       "2014-12-31 03:00:00  0.094964  0.001527  0.175653  0.297525  0.000747   \n",
       "2014-12-31 04:00:00  0.153067  0.001534  0.175296  0.430856  0.000750   \n",
       "2014-12-31 05:00:00  0.121212  0.001555  0.175606  0.551998  0.000751   \n",
       "2014-12-31 06:00:00  0.136761  0.001521  0.175529  0.789388  0.000741   \n",
       "2014-12-31 07:00:00  0.091378  0.001534  0.174759  1.125684  0.000744   \n",
       "2014-12-31 08:00:00  0.028369  0.001529  0.175063  0.982127  0.000741   \n",
       "2014-12-31 09:00:00  0.061677  0.001505  0.175371  0.527407  0.000735   \n",
       "2014-12-31 10:00:00  0.034764  0.001516  0.175343  0.488802  0.000733   \n",
       "2014-12-31 11:00:00  0.041713  0.001521  0.175371  0.856548  0.000735   \n",
       "2014-12-31 12:00:00  0.061076  0.001521  0.175809  0.694797  0.000745   \n",
       "2014-12-31 13:00:00  0.147793  0.001558  0.175559  1.011530  0.000747   \n",
       "2014-12-31 14:00:00  0.126588  0.001578  0.175855  0.733278  0.000756   \n",
       "2014-12-31 15:00:00  0.055026  0.001537  0.175230  0.817938  0.000730   \n",
       "2014-12-31 16:00:00  0.106658  0.001513  0.174970  0.401274  0.000743   \n",
       "2014-12-31 17:00:00  0.114446  0.001555  0.175794  0.347431  0.000745   \n",
       "2014-12-31 18:00:00  0.179299  0.001521  0.175156  0.468635  0.000736   \n",
       "2014-12-31 19:00:00  0.137878  0.001534  0.175653  0.394912  0.000753   \n",
       "2014-12-31 20:00:00  0.156473  0.001508  0.175296  0.964471  0.000745   \n",
       "2014-12-31 21:00:00  0.101617  0.001524  0.175230  1.127009  0.000736   \n",
       "2014-12-31 22:00:00  0.071081  0.001526  0.175389  0.503558  0.000753   \n",
       "\n",
       "                     NPWD2472  NPWD2481  NPWD2482  NPWD2491  NPWD2501  \\\n",
       "ut_ms                                                                   \n",
       "2014-12-11 03:00:00  0.002018  0.000573  0.001915  0.250222  0.005270   \n",
       "2014-12-11 04:00:00  0.001916  0.000567  0.001911  0.293467  0.005268   \n",
       "2014-12-11 05:00:00  0.001784  0.000577  0.001912  0.109192  0.005261   \n",
       "2014-12-11 06:00:00  0.001869  0.000577  0.001911  0.153566  0.005179   \n",
       "2014-12-11 07:00:00  0.001739  0.000571  0.001915  0.154937  0.005243   \n",
       "2014-12-11 08:00:00  0.001869  0.000573  0.001901  0.176760  0.005250   \n",
       "2014-12-11 09:00:00  0.001736  0.000572  0.001889  0.300233  0.005261   \n",
       "2014-12-11 10:00:00  0.001821  0.000572  0.001901  0.191653  0.005259   \n",
       "2014-12-11 11:00:00  0.001545  0.000578  0.001951  0.315071  0.005216   \n",
       "2014-12-11 12:00:00  0.001733  0.000573  0.001921  0.108283  0.005277   \n",
       "2014-12-11 13:00:00  0.001928  0.000567  0.001922  0.132422  0.005216   \n",
       "2014-12-11 14:00:00  0.002239  0.000566  0.001892  0.184174  0.005250   \n",
       "2014-12-11 15:00:00  0.001543  0.000577  0.001909  0.162479  0.005243   \n",
       "2014-12-11 16:00:00  0.002806  0.000576  0.001966  0.191965  0.005401   \n",
       "2014-12-11 17:00:00  0.001870  0.000572  0.001922  0.162975  0.005261   \n",
       "2014-12-11 18:00:00  0.001779  0.000567  0.001921  0.301563  0.005206   \n",
       "2014-12-11 19:00:00  0.002073  0.000586  0.001941  0.044339  0.005351   \n",
       "2014-12-11 20:00:00  0.001541  0.000569  0.001892  0.138640  0.005223   \n",
       "2014-12-11 21:00:00  0.002160  0.000582  0.001925  0.124385  0.005315   \n",
       "2014-12-11 22:00:00  0.001681  0.000556  0.001853  0.157216  0.005108   \n",
       "2014-12-11 23:00:00  0.001390  0.000556  0.001847  0.162316  0.005109   \n",
       "2014-12-12 00:00:00  0.001869  0.000573  0.001908  0.180173  0.005277   \n",
       "2014-12-12 01:00:00  0.001453  0.000567  0.001899  0.262145  0.005198   \n",
       "2014-12-12 02:00:00  0.001781  0.000565  0.001869  0.236772  0.005241   \n",
       "2014-12-12 03:00:00  0.001874  0.000577  0.001876  0.082625  0.005306   \n",
       "2014-12-12 04:00:00  0.001545  0.000569  0.001892  0.142301  0.005197   \n",
       "2014-12-12 05:00:00  0.001650  0.000574  0.001912  0.154930  0.005207   \n",
       "2014-12-12 06:00:00  0.002016  0.000571  0.001924  0.191603  0.005250   \n",
       "2014-12-12 07:00:00  0.001919  0.000566  0.001909  0.258488  0.005189   \n",
       "2014-12-12 08:00:00  0.002107  0.000578  0.001918  0.308590  0.005215   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2014-12-30 17:00:00  0.001831  0.000568  0.001909  0.200769  0.005225   \n",
       "2014-12-30 18:00:00  0.001408  0.000577  0.001901  0.032638  0.005135   \n",
       "2014-12-30 19:00:00  0.001734  0.000563  0.001886  0.116687  0.005225   \n",
       "2014-12-30 20:00:00  0.001680  0.000566  0.001876  0.153516  0.005143   \n",
       "2014-12-30 21:00:00  0.002490  0.000580  0.001971  0.178714  0.005333   \n",
       "2014-12-30 22:00:00  0.002054  0.000557  0.001898  0.168664  0.005206   \n",
       "2014-12-30 23:00:00  0.001695  0.000577  0.001931  0.284815  0.005342   \n",
       "2014-12-31 00:00:00  0.001496  0.000575  0.001914  0.274715  0.005170   \n",
       "2014-12-31 01:00:00  0.001918  0.000559  0.001915  0.177813  0.005297   \n",
       "2014-12-31 02:00:00  0.001631  0.000567  0.001901  0.255745  0.005170   \n",
       "2014-12-31 03:00:00  0.001737  0.000574  0.001925  0.136090  0.005270   \n",
       "2014-12-31 04:00:00  0.002104  0.000579  0.001914  0.282714  0.005277   \n",
       "2014-12-31 05:00:00  0.002252  0.000574  0.001892  0.193292  0.005234   \n",
       "2014-12-31 06:00:00  0.002148  0.000576  0.001918  0.225703  0.005277   \n",
       "2014-12-31 07:00:00  0.001554  0.000566  0.001935  0.166306  0.005297   \n",
       "2014-12-31 08:00:00  0.001545  0.000571  0.001888  0.115826  0.005179   \n",
       "2014-12-31 09:00:00  0.001968  0.000573  0.001902  0.147442  0.005261   \n",
       "2014-12-31 10:00:00  0.001871  0.000571  0.001914  0.153874  0.005135   \n",
       "2014-12-31 11:00:00  0.001690  0.000568  0.001896  0.155158  0.005180   \n",
       "2014-12-31 12:00:00  0.002010  0.000582  0.001911  0.153709  0.005268   \n",
       "2014-12-31 13:00:00  0.001883  0.000584  0.001928  0.277490  0.005306   \n",
       "2014-12-31 14:00:00  0.002005  0.000597  0.001973  0.176978  0.005419   \n",
       "2014-12-31 15:00:00  0.001744  0.000576  0.001905  0.147366  0.005243   \n",
       "2014-12-31 16:00:00  0.001871  0.000568  0.001895  0.191825  0.005241   \n",
       "2014-12-31 17:00:00  0.001739  0.000582  0.001931  0.177962  0.005315   \n",
       "2014-12-31 18:00:00  0.001962  0.000580  0.001892  0.308536  0.005223   \n",
       "2014-12-31 19:00:00  0.001881  0.000573  0.001938  0.189179  0.005306   \n",
       "2014-12-31 20:00:00  0.001689  0.000571  0.001918  0.259449  0.005179   \n",
       "2014-12-31 21:00:00  0.001690  0.000575  0.001925  0.147062  0.005261   \n",
       "2014-12-31 22:00:00  0.001687  0.000577  0.001918  0.146262  0.005286   \n",
       "\n",
       "                       ...     D3POCM  D2PLND  D5PPHB  D7PLTS  D8PLTP  SPOT  \\\n",
       "ut_ms                  ...                                                    \n",
       "2014-12-11 03:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 04:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 05:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 06:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 07:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 08:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 09:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 10:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 11:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 12:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 13:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 14:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 15:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 16:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 17:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 18:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 19:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 20:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 21:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 22:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-11 23:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-12 00:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-12 01:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-12 02:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-12 03:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-12 04:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-12 05:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-12 06:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-12 07:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-12 08:00:00    ...          0       0       0       0       0     0   \n",
       "...                    ...        ...     ...     ...     ...     ...   ...   \n",
       "2014-12-30 17:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-30 18:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-30 19:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-30 20:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-30 21:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-30 22:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-30 23:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 00:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 01:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 02:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 03:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 04:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 05:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 06:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 07:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 08:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 09:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 10:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 11:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 12:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 13:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 14:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 15:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 16:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 17:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 18:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 19:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 20:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 21:00:00    ...          0       0       0       0       0     0   \n",
       "2014-12-31 22:00:00    ...          0       0       0       0       0     0   \n",
       "\n",
       "                     D9PSPO      usbx      usby      usbz  \n",
       "ut_ms                                                      \n",
       "2014-12-11 03:00:00       0 -0.885074 -0.015705 -0.465185  \n",
       "2014-12-11 04:00:00       0  0.229725 -0.297169  0.926778  \n",
       "2014-12-11 05:00:00       0  0.682524  0.585007 -0.438096  \n",
       "2014-12-11 06:00:00       0  0.693310  0.493665 -0.524992  \n",
       "2014-12-11 07:00:00       0 -0.343933  0.397570 -0.850675  \n",
       "2014-12-11 08:00:00       0  0.757616  0.154589  0.634129  \n",
       "2014-12-11 09:00:00       0 -0.224307 -0.950424  0.215360  \n",
       "2014-12-11 10:00:00       0 -0.530428  0.724253 -0.440571  \n",
       "2014-12-11 11:00:00       0  0.520810  0.113966 -0.846031  \n",
       "2014-12-11 12:00:00       0 -0.131807  0.054685 -0.989766  \n",
       "2014-12-11 13:00:00       0  0.690428  0.509820 -0.513219  \n",
       "2014-12-11 14:00:00       0  0.690109  0.514692 -0.508764  \n",
       "2014-12-11 15:00:00       0  0.690109  0.514692 -0.508764  \n",
       "2014-12-11 16:00:00       0  0.689335  0.519060 -0.505365  \n",
       "2014-12-11 17:00:00       0 -0.985110 -0.161523  0.058896  \n",
       "2014-12-11 18:00:00       0 -0.985110 -0.161523  0.058896  \n",
       "2014-12-11 19:00:00       0 -0.740896  0.657717 -0.135946  \n",
       "2014-12-11 20:00:00       0  0.687305  0.527384 -0.499477  \n",
       "2014-12-11 21:00:00       0  0.686714  0.532478 -0.494864  \n",
       "2014-12-11 22:00:00       0  0.685437  0.536481 -0.492305  \n",
       "2014-12-11 23:00:00       0  0.685437  0.536481 -0.492305  \n",
       "2014-12-12 00:00:00       0  0.669669 -0.492722 -0.555669  \n",
       "2014-12-12 01:00:00       0  0.669669 -0.492722 -0.555669  \n",
       "2014-12-12 02:00:00       0 -0.704083 -0.699514 -0.122256  \n",
       "2014-12-12 03:00:00       0 -0.726133  0.223954  0.650058  \n",
       "2014-12-12 04:00:00       0  0.682456  0.551079 -0.480173  \n",
       "2014-12-12 05:00:00       0  0.681244  0.555850 -0.476379  \n",
       "2014-12-12 06:00:00       0  0.681244  0.555850 -0.476379  \n",
       "2014-12-12 07:00:00       0 -0.254060 -0.847400  0.466225  \n",
       "2014-12-12 08:00:00       0  0.867239  0.249444  0.430900  \n",
       "...                     ...       ...       ...       ...  \n",
       "2014-12-30 17:00:00       0 -0.989760 -0.098915 -0.102910  \n",
       "2014-12-30 18:00:00       0  0.827998 -0.328984 -0.454080  \n",
       "2014-12-30 19:00:00       0 -0.526083 -0.633256  0.567648  \n",
       "2014-12-30 20:00:00       0 -0.516009 -0.642768  0.566201  \n",
       "2014-12-30 21:00:00       0 -0.505809 -0.652130  0.564698  \n",
       "2014-12-30 22:00:00       0 -0.505809 -0.652130  0.564698  \n",
       "2014-12-30 23:00:00       0 -0.447202 -0.865417 -0.225974  \n",
       "2014-12-31 00:00:00       0  0.870309 -0.491546  0.030735  \n",
       "2014-12-31 01:00:00       0  0.179477 -0.213799  0.960249  \n",
       "2014-12-31 02:00:00       0 -0.814450  0.561373  0.146735  \n",
       "2014-12-31 03:00:00       0  0.872542 -0.430147  0.231611  \n",
       "2014-12-31 04:00:00       0 -0.810199 -0.478498  0.338553  \n",
       "2014-12-31 05:00:00       0  0.909400  0.386019 -0.154857  \n",
       "2014-12-31 06:00:00       0 -0.964785 -0.214806 -0.151819  \n",
       "2014-12-31 07:00:00       0 -0.440630  0.417733  0.794572  \n",
       "2014-12-31 08:00:00       0  0.437760  0.730833 -0.523687  \n",
       "2014-12-31 09:00:00       0  0.356817 -0.629448  0.690273  \n",
       "2014-12-31 10:00:00       0  0.187903 -0.320970 -0.928262  \n",
       "2014-12-31 11:00:00       0  0.952969 -0.225019  0.203019  \n",
       "2014-12-31 12:00:00       0  0.776475 -0.483831  0.403724  \n",
       "2014-12-31 13:00:00       0 -0.138345 -0.916342  0.375738  \n",
       "2014-12-31 14:00:00       0  0.356568 -0.725765  0.588324  \n",
       "2014-12-31 15:00:00       0 -0.581641 -0.287230 -0.761047  \n",
       "2014-12-31 16:00:00       0 -0.581641 -0.287230 -0.761047  \n",
       "2014-12-31 17:00:00       0 -0.669814 -0.353815 -0.652812  \n",
       "2014-12-31 18:00:00       0 -0.808397 -0.501676  0.307921  \n",
       "2014-12-31 19:00:00       0  0.883140  0.177234 -0.434340  \n",
       "2014-12-31 20:00:00       0 -0.332083 -0.124844  0.934952  \n",
       "2014-12-31 21:00:00       0  0.383805 -0.918458  0.095539  \n",
       "2014-12-31 22:00:00       0 -0.342380 -0.774606  0.531753  \n",
       "\n",
       "[500 rows x 81 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tail(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dates = train_data.index < '2014-12-01 00:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54632, 81), (743, 81))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_data[train_dates]\n",
    "valid_df = train_data[~train_dates]\n",
    "\n",
    "train_df.shape, valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sunmars_km',\n",
       " 'earthmars_km',\n",
       " 'sunmarsearthangle_deg',\n",
       " 'solarconstantmars',\n",
       " 'eclipseduration_min',\n",
       " 'occultationduration_min',\n",
       " 'sa',\n",
       " 'sx',\n",
       " 'sy',\n",
       " 'sz',\n",
       " 'dmop_count_24h_AAAA',\n",
       " 'dmop_count_24h_AACF',\n",
       " 'dmop_count_24h_ADMC',\n",
       " 'dmop_count_24h_AHHH',\n",
       " 'dmop_count_24h_AMMM',\n",
       " 'dmop_count_24h_AOOO',\n",
       " 'dmop_count_24h_APSF',\n",
       " 'dmop_count_24h_APWF',\n",
       " 'dmop_count_24h_ASEQ',\n",
       " 'dmop_count_24h_ASSS',\n",
       " 'dmop_count_24h_ASXX',\n",
       " 'dmop_count_24h_ATMB',\n",
       " 'dmop_count_24h_ATTT',\n",
       " 'dmop_count_24h_AVVV',\n",
       " 'dmop_count_24h_AXXX',\n",
       " 'dmop_count_24h_sum',\n",
       " 'flagcomms',\n",
       " 'EARTH',\n",
       " 'SLEW',\n",
       " 'NADIR',\n",
       " 'MAINTENANCE',\n",
       " 'INERTIAL',\n",
       " 'ACROSS_TRACK',\n",
       " 'WARMUP',\n",
       " 'D1PVMC',\n",
       " 'RADIO_SCIENCE',\n",
       " 'SPECULAR',\n",
       " 'D4PNPO',\n",
       " 'D3POCM',\n",
       " 'D2PLND',\n",
       " 'D5PPHB',\n",
       " 'D7PLTS',\n",
       " 'D8PLTP',\n",
       " 'SPOT',\n",
       " 'D9PSPO',\n",
       " 'usbx',\n",
       " 'usby',\n",
       " 'usbz']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_columns = filter(lambda x: \"NPWD\" not in x \n",
    "                   and 'ut_ms' not in x, train_df.columns)\n",
    "x_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NPWD2372',\n",
       " 'NPWD2401',\n",
       " 'NPWD2402',\n",
       " 'NPWD2451',\n",
       " 'NPWD2471',\n",
       " 'NPWD2472',\n",
       " 'NPWD2481',\n",
       " 'NPWD2482',\n",
       " 'NPWD2491',\n",
       " 'NPWD2501',\n",
       " 'NPWD2531',\n",
       " 'NPWD2532',\n",
       " 'NPWD2551',\n",
       " 'NPWD2552',\n",
       " 'NPWD2561',\n",
       " 'NPWD2562',\n",
       " 'NPWD2691',\n",
       " 'NPWD2692',\n",
       " 'NPWD2721',\n",
       " 'NPWD2722',\n",
       " 'NPWD2742',\n",
       " 'NPWD2771',\n",
       " 'NPWD2791',\n",
       " 'NPWD2792',\n",
       " 'NPWD2801',\n",
       " 'NPWD2802',\n",
       " 'NPWD2821',\n",
       " 'NPWD2851',\n",
       " 'NPWD2852',\n",
       " 'NPWD2871',\n",
       " 'NPWD2872',\n",
       " 'NPWD2881',\n",
       " 'NPWD2882']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_columns = filter(lambda x: \"NPWD\"  in x, train_df.columns)\n",
    "y_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create train/valid datasets\n",
    "X_train = train_df[x_columns]\n",
    "y_train = train_df[y_columns]\n",
    "\n",
    "X_valid = valid_df[x_columns]\n",
    "y_valid = valid_df[y_columns]\n",
    "\n",
    "X_test = test_data[x_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter_dict = {    # Parameters for XGBRegressor\n",
    "    \"n_estimators\":200,\n",
    "    \"silent\":1,\n",
    "    \"nthread\":-1,\n",
    "    \"gamma\":0.001,\n",
    "    \"max_depth\":6,\n",
    "    \"min_child_weight\":2,\n",
    "    \"max_delta_step\":1,\n",
    "    \"reg_lambda\":0.1,\n",
    "    \"reg_alpha\":0.1,\n",
    "    'max_depth': 3,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bylevel': 0.4,\n",
    "    'colsample_bytree': 0.4,\n",
    "}\n",
    "\n",
    "#Create lists to check regressors\n",
    "\n",
    "names = [\n",
    "    \"ExtraTreesRegressor\",\n",
    "    \"RandomForestRegressor\",\n",
    "    #\"SVR_linear\",\n",
    "    #\"SVR_rbf\",\n",
    "    \"ElasticNet\",\n",
    "    \"Ridge\",\n",
    "    \"HuberRegressor\",\n",
    "    \"RANSACRegressor\",\n",
    "    #\"SGDRegressor\",\n",
    "    \"XGBRegressor\",\n",
    "    \"GradientBoostingRegressor\"\n",
    "]\n",
    "\n",
    "ensemble = [\n",
    "    \"AdaBoostRegressor\"\n",
    "]\n",
    "\n",
    "regressors = [\n",
    "    ExtraTreesRegressor(n_estimators=20, criterion='mse', max_depth=10,\n",
    "                       min_samples_split=3, min_samples_leaf=4, bootstrap=True),\n",
    "    RandomForestRegressor(n_estimators=20, criterion='mse', max_depth=10,\n",
    "                         min_samples_split=3, min_samples_leaf=4, bootstrap=True),\n",
    "    #SVR(kernel='linear', C=10.0, cache_size=400, max_iter=10000),\n",
    "    #SVR(C=100.0, max_iter=10000),\n",
    "    ElasticNet(alpha=1.5, l1_ratio=0.1, normalize=True, warm_start=True),\n",
    "    Ridge(alpha=0.8, normalize=True),\n",
    "    HuberRegressor(warm_start=True),\n",
    "    RANSACRegressor(max_trials=150, loss='squared_loss'),\n",
    "    #SGDRegressor(loss='huber', penalty='elasticnet', alpha=0.001, n_iter=30,\n",
    "    #            learning_rate='optimal'),\n",
    "    xgb.XGBRegressor(**parameter_dict),\n",
    "    GradientBoostingRegressor()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.as_matrix()\n",
    "y_train = y_train.as_matrix()\n",
    "\n",
    "X_valid = X_valid.as_matrix()\n",
    "y_valid = y_valid.as_matrix()\n",
    "\n",
    "X_test = X_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Own RMSE function - we don't operate at pandas DataFrames\n",
    "def RMSE_func(y_true, y_pred, axis=None):\n",
    "    diff = y_true - y_pred\n",
    "    rmse = np.sqrt(np.mean(diff**2, axis=axis))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ExtraTreesRegressor\n",
      "Fitting RandomForestRegressor\n",
      "Fitting ElasticNet\n",
      "Fitting Ridge\n",
      "Fitting HuberRegressor\n",
      "Fitting RANSACRegressor\n",
      "Fitting XGBRegressor\n",
      "Fitting GradientBoostingRegressor\n",
      "Loss of ExtraTreesRegressor = 0.0937262958253\n",
      "Loss of RandomForestRegressor = 0.0971771594947\n",
      "Loss of ElasticNet = 0.115479233327\n",
      "Loss of Ridge = 0.0997393523542\n",
      "Loss of HuberRegressor = 0.143163729309\n",
      "Loss of RANSACRegressor = 0.118197640637\n",
      "Loss of XGBRegressor = 0.0922075881837\n",
      "Loss of GradientBoostingRegressor = 0.0948659588796\n"
     ]
    }
   ],
   "source": [
    "losses = {}\n",
    "\n",
    "for name, reg in zip(names, regressors):\n",
    "    print(\"Fitting\",name)\n",
    "    #print(\"\\tUsing\",ensemble[0])\n",
    "    \n",
    "    #rega = AdaBoostRegressor(reg, n_estimators=70)\n",
    "    \n",
    "    regress = MultiOutputRegressor(reg, n_jobs=-1)\n",
    "    regress.fit(X_train, y_train)\n",
    "    \n",
    "    predicts = regress.predict(X_valid)\n",
    "    losses[name] = RMSE_func(y_valid, predicts)\n",
    "    \n",
    "for name in names:\n",
    "    print(\"Loss of\",name,\"=\",losses[name])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7979, 33)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Simple RNN Network Class - Using GRU Cells\n",
    "\n",
    "class SimpleRNNNetwork(object):\n",
    "    def __init__(self, input_shape, output_shape=1, layer_size=200, hidden_layers = 2):\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        \n",
    "        input_data = Input(shape=(input_shape,))\n",
    "        hidden = Reshape((1,-1))(input_data)\n",
    "        for _ in xrange(hidden_layers):\n",
    "            hidden = Bidirectional(GRU(layer_size, recurrent_dropout=0.1, return_sequences=True))(hidden)\n",
    "        \n",
    "        hidden = Bidirectional(GRU(int(layer_size/2), recurrent_dropout=0.1))(hidden)\n",
    "        \n",
    "        hidden = Dropout(0.4)(hidden)\n",
    "        output = Dense(output_shape, activation='linear')(hidden)\n",
    "        \n",
    "        self.model = Model(input_data, output)\n",
    "        self.loss = root_mean_squared_error\n",
    "        \n",
    "    def fit(self, x, y, valid_data, batch_size=64, lr_scheme=[0.01,0.005,0.001], epochs_scheme=[3,2,2]):\n",
    "        \n",
    "        for lr, epochs in zip(lr_scheme, epochs_scheme):\n",
    "            print(\"Running {} epochs with learning rate {}\".format(epochs, lr))\n",
    "            self.model.compile(optimizer=Adam(lr=lr), loss=self.loss)\n",
    "            self.model.fit(x=x, y=y, batch_size=batch_size, epochs=epochs, validation_data=valid_data)\n",
    "            \n",
    "    def predict(self, x):\n",
    "        batch_size=64\n",
    "        return self.model.predict(x, batch_size=batch_size)\n",
    "    \n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalzation\n",
    "X_norm_train = normalize_features(X_train, method='uniform_symmetric')\n",
    "X_norm_valid = normalize_features(X_valid, method='uniform_symmetric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect Regressors\n",
    "winners = []\n",
    "names = losses.keys()\n",
    "for name in names:\n",
    "    if losses[name] < 0.12:\n",
    "        winners.append(name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GradientBoostingRegressor',\n",
       " 'Ridge',\n",
       " 'XGBRegressor',\n",
       " 'RANSACRegressor',\n",
       " 'ElasticNet',\n",
       " 'RandomForestRegressor',\n",
       " 'ExtraTreesRegressor']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "winners.append(\"XGBRegressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GradientBoostingRegressor',\n",
       " 'Ridge',\n",
       " 'ExtraTreesRegressor',\n",
       " 'SimpleRNNNetwork',\n",
       " 'XGBRegressor']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Not used in this code\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GradientBoostingRegressor()\n",
    "\n",
    "#Attempt to create GridSearch - dictionaries of parameters\n",
    "gbr_params = [\n",
    "    {\n",
    "    \"loss\":\"ls\",\n",
    "    \"learning_rate\":0.1,\n",
    "    \"n_estimators\":200,\n",
    "    \"max_depth\":4,\n",
    "    \"min_samples_split\":3,\n",
    "    \"min_samples_leaf\":2,\n",
    "    \"subsample\":0.8,\n",
    "        },\n",
    "    {\n",
    "    \"loss\":\"huber\",\n",
    "    \"learning_rate\":0.001,\n",
    "    \"n_estimators\":100,\n",
    "    \"max_depth\":6,\n",
    "    \"min_samples_split\":2,\n",
    "    \"min_samples_leaf\":1,\n",
    "    \"subsample\":0.6,\n",
    "    },\n",
    "    {\n",
    "    \"loss\":\"quantile\",\n",
    "    \"learning_rate\":0.05,\n",
    "    \"n_estimators\":200,\n",
    "    \"max_depth\":4,\n",
    "    \"min_samples_split\":4,\n",
    "    \"min_samples_leaf\":5,\n",
    "    \"subsample\":1,\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set: 1\n",
      "\n",
      "Loss = 0.0974939066871\n",
      "Testing set: 2\n",
      "\n",
      "Loss = 0.11771073327\n",
      "Testing set: 3\n",
      "\n",
      "Loss = 0.148266305474\n"
     ]
    }
   ],
   "source": [
    "#GradientBoostingRegressor test\n",
    "\n",
    "for i, params in enumerate(gbr_params):\n",
    "    print(\"Testing set:\",(i+1))\n",
    "    reg = GradientBoostingRegressor(**params)\n",
    "    reg = MultiOutputRegressor(reg, n_jobs=-1)\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    predicts=reg.predict(X_valid)\n",
    "    loss = RMSE_func(y_valid, predicts)\n",
    "    print(\"\\nLoss =\",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GradientBoostingRegressor',\n",
       " 'Ridge',\n",
       " 'ExtraTreesRegressor',\n",
       " 'SimpleRNNNetwork',\n",
       " 'XGBRegressor']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Similar to above\n",
    "ridge_params = [\n",
    "    {\n",
    "        \"alpha\":1.0, \n",
    "        \"fit_intercept\":True, \n",
    "        \"normalize\":False, \n",
    "        \"copy_X\":True, \n",
    "        \"max_iter\":None, \n",
    "        \"tol\":0.001, \n",
    "        \"solver\":'auto'\n",
    "    },\n",
    "    {\n",
    "        \"alpha\":10.0, \n",
    "        \"fit_intercept\":True, \n",
    "        \"normalize\":True, \n",
    "        \"copy_X\":True, \n",
    "        \"max_iter\":None, \n",
    "        \"tol\":0.0001, \n",
    "        \"solver\":'cholesky'\n",
    "    },\n",
    "    {\n",
    "        \"alpha\":0.1, \n",
    "        \"fit_intercept\":False, \n",
    "        \"normalize\":True, \n",
    "        \"copy_X\":True, \n",
    "        \"max_iter\":None, \n",
    "        \"tol\":0.01, \n",
    "        \"solver\":'sag'\n",
    "    },\n",
    "    {\n",
    "        \"alpha\":1.0, \n",
    "        \"fit_intercept\":True, \n",
    "        \"normalize\":True, \n",
    "        \"copy_X\":True, \n",
    "        \"max_iter\":None, \n",
    "        \"tol\":0.005, \n",
    "        \"solver\":'lsqr'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set: 1\n",
      "\n",
      "Loss = 0.0983965932797\n",
      "Testing set: 2\n",
      "\n",
      "Loss = 0.107291292813\n",
      "Testing set: 3\n",
      "\n",
      "Loss = 0.143402379367\n",
      "Testing set: 4\n",
      "\n",
      "Loss = 0.100605561783\n"
     ]
    }
   ],
   "source": [
    "for i, params in enumerate(ridge_params):\n",
    "    print(\"Testing set:\",(i+1))\n",
    "    reg = Ridge(**params)\n",
    "    reg = MultiOutputRegressor(reg, n_jobs=-1)\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    predicts=reg.predict(X_valid)\n",
    "    loss = RMSE_func(y_valid, predicts)\n",
    "    print(\"\\nLoss =\",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GradientBoostingRegressor',\n",
       " 'Ridge',\n",
       " 'ExtraTreesRegressor',\n",
       " 'SimpleRNNNetwork',\n",
       " 'XGBRegressor']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb.XGBRegressor()\n",
    "\n",
    "xgb_params = [{\n",
    "    \"max_depth\":6,\n",
    "    \"learning_rate\":0.1,\n",
    "    \"n_estimators\":100,\n",
    "    \"silent\":True,\n",
    "    \"objective\":'reg:linear',\n",
    "    \"nthread\":-1,\n",
    "    \"gamma\":0,\n",
    "    \"min_child_weight\":1,\n",
    "    \"max_delta_step\":0,\n",
    "    \"subsample\":1,\n",
    "    \"colsample_bytree\":1,\n",
    "    \"colsample_bylevel\":1,\n",
    "    \"reg_alpha\":0,\n",
    "    \"reg_lambda\":1,\n",
    "    \"scale_pos_weight\":1,\n",
    "    \"base_score\":0.5\n",
    "},\n",
    "    {\n",
    "    \"max_depth\":3,\n",
    "    \"learning_rate\":0.1,\n",
    "    \"n_estimators\":200,\n",
    "    \"silent\":True,\n",
    "    \"objective\":\"reg:linear\",\n",
    "    \"nthread\":-1,\n",
    "    \"gamma\":0.001,\n",
    "    \"min_child_weight\":2,\n",
    "    \"max_delta_step\":1,\n",
    "    \"subsample\":0.7,\n",
    "    \"colsample_bytree\":0.4,\n",
    "    \"colsample_bylevel\":0.4,\n",
    "    \"reg_alpha\":0.1,\n",
    "    \"reg_lambda\":0.1,\n",
    "    \"scale_pos_weight\":1,\n",
    "    \"base_score\":0.5\n",
    "},\n",
    "    {\n",
    "    \"max_depth\":4,\n",
    "    \"learning_rate\":0.01,\n",
    "    \"n_estimators\":150,\n",
    "    \"silent\":True,\n",
    "    \"objective\":'reg:linear',\n",
    "    \"nthread\":-1,\n",
    "    \"gamma\":0.01,\n",
    "    \"min_child_weight\":3,\n",
    "    \"max_delta_step\":0.5,\n",
    "    \"subsample\":0.9,\n",
    "    \"colsample_bytree\":0.7,\n",
    "    \"colsample_bylevel\":0.7,\n",
    "    \"reg_alpha\":0.3,\n",
    "    \"reg_lambda\":0.15,\n",
    "    \"scale_pos_weight\":1,\n",
    "    \"base_score\":0.7\n",
    "},\n",
    "    {\n",
    "    \"max_depth\":7,\n",
    "    \"learning_rate\":0.001,\n",
    "    \"n_estimators\":250,\n",
    "    \"silent\":True,\n",
    "    \"objective\":'reg:linear',\n",
    "    \"nthread\":-1,\n",
    "    \"gamma\":0.05,\n",
    "    \"min_child_weight\":4,\n",
    "    \"max_delta_step\":2,\n",
    "    \"subsample\":1,\n",
    "    \"colsample_bytree\":1,\n",
    "    \"colsample_bylevel\":1,\n",
    "    \"reg_alpha\":0.01,\n",
    "    \"reg_lambda\":0.01,\n",
    "    \"scale_pos_weight\":0.8,\n",
    "    \"base_score\":0.5\n",
    "},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set: 1\n",
      "\n",
      "Loss = 0.120865871822\n",
      "Testing set: 2\n",
      "\n",
      "Loss = 0.113375108287\n",
      "Testing set: 3\n",
      "\n",
      "Loss = 0.181657261922\n",
      "Testing set: 4\n",
      "\n",
      "Loss = 0.360203318585\n"
     ]
    }
   ],
   "source": [
    "for i, params in enumerate(xgb_params):\n",
    "    print(\"Testing set:\",(i+1))\n",
    "    reg = xgb.XGBRegressor(**params)\n",
    "    reg = MultiOutputRegressor(reg, n_jobs=-1)\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    predicts=reg.predict(X_valid)\n",
    "    loss = RMSE_func(y_valid, predicts)\n",
    "    print(\"\\nLoss =\",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Class as RNN Network but using LSTM cells\n",
    "class SimpleLSTMNetwork(object):\n",
    "    def __init__(self, input_shape, output_shape=33, layer_size=200, hidden_layers = 2):\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        \n",
    "        input_data = Input(shape=(input_shape,))\n",
    "        hidden = Reshape((1,-1))(input_data)\n",
    "        hidden = GaussianNoise(1)(hidden)\n",
    "        hidden = BatchNormalization()(hidden)\n",
    "        for _ in xrange(hidden_layers):\n",
    "            hidden = Bidirectional(LSTM(layer_size, recurrent_dropout=0.2, dropout=0.4, return_sequences=True))(hidden)\n",
    "        \n",
    "        hidden = Bidirectional(LSTM(int(layer_size/2), recurrent_dropout=0.2))(hidden)\n",
    "        \n",
    "        hidden = Dropout(0.4)(hidden)\n",
    "        output = Dense(output_shape, activation='linear')(hidden)\n",
    "        \n",
    "        self.model = Model(input_data, output)\n",
    "        self.loss = root_mean_squared_error\n",
    "        \n",
    "    def fit(self, x, y, valid_data, batch_size=64, lr_scheme=[0.01,0.005,0.001], epochs_scheme=[4,3,2]):\n",
    "        \n",
    "        for lr, epochs in zip(lr_scheme, epochs_scheme):\n",
    "            print(\"Running {} epochs with learning rate {}\".format(epochs, lr))\n",
    "            self.model.compile(optimizer=Adam(lr=lr), loss=self.loss)\n",
    "            self.model.fit(x=x, y=y, batch_size=batch_size, epochs=epochs, validation_data=valid_data)\n",
    "            \n",
    "    def predict(self, x):\n",
    "        batch_size=64\n",
    "        return self.model.predict(x, batch_size=batch_size)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slstm_nets = []\n",
    "for _ in xrange(5):\n",
    "    slstm_nets.append(SimpleLSTMNetwork(X_train.shape[1], y_train.shape[1], layer_size=250, hidden_layers=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "cross_vals = X_train.shape[0]//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In learning time you can check results - simple cv evaluation\n",
    "for i in xrange(batch_size):\n",
    "    x_tre = X_norm_train[i*cross_vals:(i+1)*cross_vals]\n",
    "    y_tre = y_train[i*cross_vals:(i+1)*cross_vals]\n",
    "    slstm_nets[i].fit(x_tre, y_tre, (X_norm_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for average output prediction\n",
    "def average_predict(predicts):        \n",
    "    preds = np.mean(predicts, axis=0)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(744, 42)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicts = average_predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17447, 33)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.13348235922\n"
     ]
    }
   ],
   "source": [
    "loss = RMSE_func(y_valid, predicts)\n",
    "print(\"Loss =\",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check of AdaBoostRegressor \n",
    "params = {\n",
    "    \"max_depth\":4,\n",
    "    \"learning_rate\":0.01,\n",
    "    \"n_estimators\":150,\n",
    "    \"silent\":True,\n",
    "    \"objective\":'reg:linear',\n",
    "    \"nthread\":-1,\n",
    "    \"gamma\":0.01,\n",
    "    \"min_child_weight\":3,\n",
    "    \"max_delta_step\":0.5,\n",
    "    \"subsample\":0.9,\n",
    "    \"colsample_bytree\":0.7,\n",
    "    \"colsample_bylevel\":0.7,\n",
    "    \"reg_alpha\":0.3,\n",
    "    \"reg_lambda\":0.15,\n",
    "    \"scale_pos_weight\":1,\n",
    "    \"base_score\":0.7\n",
    "}\n",
    "\n",
    "reg = xgb.XGBRegressor(**params)\n",
    "\n",
    "ada = AdaBoostRegressor(reg, n_estimators=50)\n",
    "regress = MultiOutputRegressor(ada, n_jobs=-1)\n",
    "\n",
    "regress.fit(X_train, y_train)\n",
    "\n",
    "predicts = regress.predict(X_valid)\n",
    "\n",
    "loss = RMSE_func(y_valid, predicts)\n",
    "print(\"Loss =\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_count = 4\n",
    "y_split = np.ceil(y_train.shape[1]/4.)\n",
    "y_split\n",
    "\n",
    "y_model_1 = y_train[:,0:9]\n",
    "y_model_2 = y_train[:,9:18]\n",
    "y_model_3 = y_train[:,18:27]\n",
    "y_model_4 = y_train[:,27:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37928, 9), (37928, 9), (37928, 9), (37928, 6))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_model_1.shape, y_model_2.shape, y_model_3.shape, y_model_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Last modification - AdaBoostRegressor used on winners\n",
    "gb_params =  {\n",
    "    \"loss\":\"ls\",\n",
    "    \"learning_rate\":0.01,\n",
    "    \"n_estimators\":250,\n",
    "    \"max_depth\":6,\n",
    "    \"min_samples_split\":2,\n",
    "    \"min_samples_leaf\":3,\n",
    "    \"subsample\":0.9,\n",
    "        }\n",
    "\n",
    "model_1 = GradientBoostingRegressor(**gb_params)\n",
    "\n",
    "rid_params = {\n",
    "        \"alpha\":1.5, \n",
    "        \"fit_intercept\":True, \n",
    "        \"normalize\":True, \n",
    "        \"copy_X\":True, \n",
    "        \"max_iter\":None, \n",
    "        \"tol\":0.005, \n",
    "        \"solver\":'auto'\n",
    "}\n",
    "\n",
    "model_2 = Ridge(**rid_params)\n",
    "\n",
    "parameter_dict = {\n",
    "    \"n_estimators\":250,\n",
    "    \"silent\":1,\n",
    "    \"nthread\":-1,\n",
    "    \"gamma\":0.01,\n",
    "    \"max_depth\":7,\n",
    "    \"min_child_weight\":2,\n",
    "    \"max_delta_step\":0.5,\n",
    "    \"reg_lambda\":0.2,\n",
    "    \"reg_alpha\":0.2,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bylevel': 1,\n",
    "    'colsample_bytree': 1,\n",
    "}\n",
    "\n",
    "\n",
    "model_3 = xgb.XGBRegressor(**parameter_dict)\n",
    "\n",
    "model_4 = SimpleRNNNetwork(X_train.shape[1], y_valid.shape[1], layer_size=250, hidden_layers=3)\n",
    "\n",
    "#model_1 = AdaBoostRegressor(model_1, n_estimators=10)\n",
    "model_2 = AdaBoostRegressor(model_2, n_estimators=20)\n",
    "\n",
    "model_1 = MultiOutputRegressor(model_1, n_jobs=-1)\n",
    "model_2 = MultiOutputRegressor(model_2, n_jobs=-1)\n",
    "model_3 = MultiOutputRegressor(model_3, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=4,\n",
       "           min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False),\n",
       " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "            max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=4,\n",
       "            min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       " ElasticNet(alpha=1.5, copy_X=True, fit_intercept=True, l1_ratio=0.1,\n",
       "       max_iter=1000, normalize=True, positive=False, precompute=False,\n",
       "       random_state=None, selection='cyclic', tol=0.0001, warm_start=True),\n",
       " Ridge(alpha=0.8, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "    normalize=True, random_state=None, solver='auto', tol=0.001),\n",
       " HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,\n",
       "         tol=1e-05, warm_start=True),\n",
       " RANSACRegressor(base_estimator=None, is_data_valid=None, is_model_valid=None,\n",
       "         loss='squared_loss', max_trials=150, min_samples=None,\n",
       "         random_state=None, residual_metric=None, residual_threshold=None,\n",
       "         stop_n_inliers=inf, stop_probability=0.99, stop_score=inf),\n",
       " XGBRegressor(base_score=0.5, colsample_bylevel=0.4, colsample_bytree=0.4,\n",
       "        gamma=0.001, learning_rate=0.1, max_delta_step=1, max_depth=3,\n",
       "        min_child_weight=2, missing=None, n_estimators=200, nthread=-1,\n",
       "        objective='reg:linear', reg_alpha=0.1, reg_lambda=0.1,\n",
       "        scale_pos_weight=1, seed=0, silent=1, subsample=0.7),\n",
       " GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "              max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val_1 = y_valid[:,0:9]\n",
    "y_val_2 = y_valid[:,9:18]\n",
    "y_val_3 = y_valid[:,18:27]\n",
    "y_val_4 = y_valid[:,27:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7979, 42)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_1, model_2,model_3, model_4]\n",
    "\n",
    "count = 0\n",
    "\n",
    "for model in models:\n",
    "    print(\"Model nb\",(count+1),\"fitting\")\n",
    "    if count < 3:\n",
    "        model.fit(X_train, y_train)\n",
    "    else:\n",
    "        model.fit(X_train, y_train, valid_data=(X_valid, y_valid))\n",
    "    print(\"\\tFinished\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 4 epochs with learning rate 0.01\n",
      "Train on 54632 samples, validate on 743 samples\n",
      "Epoch 1/4\n",
      "54632/54632 [==============================] - 71s - loss: 0.0987 - val_loss: 0.0996\n",
      "Epoch 2/4\n",
      "54632/54632 [==============================] - 67s - loss: 0.0903 - val_loss: 0.0956\n",
      "Epoch 3/4\n",
      "54632/54632 [==============================] - 71s - loss: 0.0914 - val_loss: 0.0986\n",
      "Epoch 4/4\n",
      "54632/54632 [==============================] - 71s - loss: 0.0924 - val_loss: 0.0993\n",
      "Running 3 epochs with learning rate 0.005\n",
      "Train on 54632 samples, validate on 743 samples\n",
      "Epoch 1/3\n",
      "54632/54632 [==============================] - 75s - loss: 0.0922 - val_loss: 0.0949\n",
      "Epoch 2/3\n",
      "54632/54632 [==============================] - 72s - loss: 0.0908 - val_loss: 0.0938\n",
      "Epoch 3/3\n",
      "54632/54632 [==============================] - 72s - loss: 0.0905 - val_loss: 0.0957\n",
      "Running 2 epochs with learning rate 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/kinshiryuu-burp/anaconda3/envs/nitinol/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/kinshiryuu-burp/anaconda3/envs/nitinol/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/kinshiryuu-burp/anaconda3/envs/nitinol/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/kinshiryuu-burp/anaconda3/envs/nitinol/lib/python2.7/inspect.py\", line 1048, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/home/kinshiryuu-burp/anaconda3/envs/nitinol/lib/python2.7/inspect.py\", line 1008, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/kinshiryuu-burp/anaconda3/envs/nitinol/lib/python2.7/inspect.py\", line 453, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/home/kinshiryuu-burp/anaconda3/envs/nitinol/lib/python2.7/inspect.py\", line 496, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/kinshiryuu-burp/anaconda3/envs/nitinol/lib/python2.7/inspect.py\", line 466, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/home/kinshiryuu-burp/anaconda3/envs/nitinol/lib/python2.7/posixpath.py\", line 366, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/home/kinshiryuu-burp/anaconda3/envs/nitinol/lib/python2.7/posixpath.py\", line 341, in normpath\n",
      "    comps = path.split('/')\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/home/kinshiryuu-burp/anaconda3/envs/nitinol/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kinshiryuu-burp/anaconda3/envs/nitinol/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1822\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1824\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1826\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kinshiryuu-burp/anaconda3/envs/nitinol/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1412\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kinshiryuu-burp/anaconda3/envs/nitinol/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1320\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m             )\n\u001b[1;32m   1322\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kinshiryuu-burp/anaconda3/envs/nitinol/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "model_5 = SimpleLSTMNetwork(X_train.shape[1], y_valid.shape[1], layer_size=200, hidden_layers=5)\n",
    "model_5.fit(X_train, y_train, valid_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_1 = model_1.predict(X_valid)\n",
    "pred_2 = model_2.predict(X_valid)\n",
    "pred_4 = model_4.predict(X_valid)\n",
    "pred_5 = model_5.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicts = average_predict([pred_1, pred_2, pred_4, pred_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(744, 33)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.0947008891887\n"
     ]
    }
   ],
   "source": [
    "loss = RMSE_func(y_valid, predicts)\n",
    "print(\"Loss =\",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir(\"../data/models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SimpleRNNNetwork at 0x7f4ee7a8d090>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../data/models/adagb_small_1.pkl\", 'wb') as f:\n",
    "    pickle.dump(model_1, f)\n",
    "    \n",
    "with open(\"../data/models/adaridge_small_.pkl\", 'wb') as f:\n",
    "    pickle.dump(model_2, f)\n",
    "    \n",
    "model_4.model.save(\"../data/models/simplernn_small.h5\")\n",
    "model_5.model.save(\"../data/models/simplelstm_small.5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"Super\" Network - hidden layers connections with first layer\n",
    "class SuperLSTMNetwork(object):\n",
    "    def __init__(self, input_shape, output_shape=33, layer_size=200):\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        \n",
    "        input_data = Input(shape=(input_shape,))\n",
    "        hidden = Reshape((1,-1))(input_data)\n",
    "        hidden = GaussianNoise(1)(hidden)\n",
    "        hidden = BatchNormalization()(hidden)\n",
    "        hidden_1 = Bidirectional(LSTM(int(layer_size), recurrent_dropout=0.2))(hidden)\n",
    "        hidden_1 = Reshape((1,-1))(hidden_1)\n",
    "        hidden_1 = BatchNormalization()(hidden_1)\n",
    "        hidden_2 = Bidirectional(GRU(int(layer_size), recurrent_dropout=0.2))(hidden_1)\n",
    "        hidden_2 = Reshape((1,-1))(hidden_2)\n",
    "        h_merge = merge([hidden_1, hidden_2],mode='concat')\n",
    "        h_merge = Reshape((1,-1))(h_merge)\n",
    "        hidden_2 = Bidirectional(GRU(int(layer_size), recurrent_dropout=0.2))(h_merge)\n",
    "        merg = merge([hidden_1, h_merge],mode='concat')\n",
    "        merg = Reshape((-1,))(merg)\n",
    "        merged = Dense(250,kernel_initializer='he_normal', activation='tanh')(merg)\n",
    "        merged = Dropout(0.4)(merged)\n",
    "        output = Dense(output_shape, activation='linear')(merged)\n",
    "        \n",
    "        self.model = Model(input_data, output)\n",
    "        self.loss = root_mean_squared_error\n",
    "        \n",
    "    def fit(self, x, y, valid_data, batch_size=64, lr_scheme=[0.01,0.005,0.001], epochs_scheme=[4,3,2]):\n",
    "        \n",
    "        for lr, epochs in zip(lr_scheme, epochs_scheme):\n",
    "            print(\"Running {} epochs with learning rate {}\".format(epochs, lr))\n",
    "            self.model.compile(optimizer=Adam(lr=lr), loss=self.loss)\n",
    "            self.model.fit(x=x, y=y, batch_size=batch_size, epochs=epochs, validation_data=valid_data)\n",
    "            \n",
    "    def predict(self, x):\n",
    "        batch_size=64\n",
    "        return self.model.predict(x, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kinshiryuu-burp/anaconda3/envs/nitinol/lib/python2.7/site-packages/ipykernel_launcher.py:16: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  app.launch_new_instance()\n",
      "/home/kinshiryuu-burp/anaconda3/envs/nitinol/lib/python2.7/site-packages/keras/legacy/layers.py:460: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 42)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)              (None, 1, 42)         0           input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gaussian_noise_2 (GaussianNoise) (None, 1, 42)         0           reshape_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 1, 42)         168         gaussian_noise_2[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional)  (None, 400)           388800      batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)              (None, 1, 400)        0           bidirectional_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 1, 400)        1600        reshape_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional) (None, 400)           721200      batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)              (None, 1, 400)        0           bidirectional_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 1, 800)        0           batch_normalization_3[0][0]      \n",
      "                                                                   reshape_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)              (None, 1, 800)        0           merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 1, 1200)       0           batch_normalization_3[0][0]      \n",
      "                                                                   reshape_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)              (None, 1200)          0           merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 250)           300250      reshape_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 250)           0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 33)            8283        dropout_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,420,301\n",
      "Trainable params: 1,419,417\n",
      "Non-trainable params: 884\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kinshiryuu-burp/anaconda3/envs/nitinol/lib/python2.7/site-packages/ipykernel_launcher.py:19: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "super_model = SuperLSTMNetwork(X_train.shape[1], y_train.shape[1])\n",
    "super_model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 4 epochs with learning rate 0.01\n",
      "Train on 7979 samples, validate on 744 samples\n",
      "Epoch 1/4\n",
      "7979/7979 [==============================] - 5s - loss: 0.3632 - val_loss: 0.1691\n",
      "Epoch 2/4\n",
      "7979/7979 [==============================] - 2s - loss: 0.1592 - val_loss: 0.1326\n",
      "Epoch 3/4\n",
      "7979/7979 [==============================] - 2s - loss: 0.1618 - val_loss: 0.1377\n",
      "Epoch 4/4\n",
      "7979/7979 [==============================] - 2s - loss: 0.1609 - val_loss: 0.1490\n",
      "Running 3 epochs with learning rate 0.005\n",
      "Train on 7979 samples, validate on 744 samples\n",
      "Epoch 1/3\n",
      "7979/7979 [==============================] - 5s - loss: 0.1293 - val_loss: 0.1116\n",
      "Epoch 2/3\n",
      "7979/7979 [==============================] - 2s - loss: 0.1183 - val_loss: 0.1088\n",
      "Epoch 3/3\n",
      "7979/7979 [==============================] - 2s - loss: 0.1193 - val_loss: 0.1070\n",
      "Running 2 epochs with learning rate 0.001\n",
      "Train on 7979 samples, validate on 744 samples\n",
      "Epoch 1/2\n",
      "7979/7979 [==============================] - 6s - loss: 0.0945 - val_loss: 0.0925\n",
      "Epoch 2/2\n",
      "7979/7979 [==============================] - 2s - loss: 0.0914 - val_loss: 0.0952\n"
     ]
    }
   ],
   "source": [
    "super_model.fit(X_train, y_train, (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.100630556242\n"
     ]
    }
   ],
   "source": [
    "predicts = super_model.predict(X_valid)\n",
    "loss = RMSE_func(y_valid, predicts)\n",
    "print(\"Loss =\",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predict = pd.read_csv(\"../data/hackathon/sample_power_zeros--2015-01-01_2015-07-01.csv\", index_col=0)\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NPWD2372</th>\n",
       "      <th>NPWD2401</th>\n",
       "      <th>NPWD2402</th>\n",
       "      <th>NPWD2451</th>\n",
       "      <th>NPWD2471</th>\n",
       "      <th>NPWD2472</th>\n",
       "      <th>NPWD2481</th>\n",
       "      <th>NPWD2482</th>\n",
       "      <th>NPWD2491</th>\n",
       "      <th>NPWD2501</th>\n",
       "      <th>...</th>\n",
       "      <th>NPWD2792</th>\n",
       "      <th>NPWD2801</th>\n",
       "      <th>NPWD2802</th>\n",
       "      <th>NPWD2821</th>\n",
       "      <th>NPWD2851</th>\n",
       "      <th>NPWD2852</th>\n",
       "      <th>NPWD2871</th>\n",
       "      <th>NPWD2872</th>\n",
       "      <th>NPWD2881</th>\n",
       "      <th>NPWD2882</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ut_ms</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1420070400000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420074000000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420077600000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420081200000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420084800000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               NPWD2372  NPWD2401  NPWD2402  NPWD2451  NPWD2471  NPWD2472  \\\n",
       "ut_ms                                                                       \n",
       "1420070400000       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1420074000000       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1420077600000       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1420081200000       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1420084800000       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "               NPWD2481  NPWD2482  NPWD2491  NPWD2501    ...     NPWD2792  \\\n",
       "ut_ms                                                    ...                \n",
       "1420070400000       0.0       0.0       0.0       0.0    ...          0.0   \n",
       "1420074000000       0.0       0.0       0.0       0.0    ...          0.0   \n",
       "1420077600000       0.0       0.0       0.0       0.0    ...          0.0   \n",
       "1420081200000       0.0       0.0       0.0       0.0    ...          0.0   \n",
       "1420084800000       0.0       0.0       0.0       0.0    ...          0.0   \n",
       "\n",
       "               NPWD2801  NPWD2802  NPWD2821  NPWD2851  NPWD2852  NPWD2871  \\\n",
       "ut_ms                                                                       \n",
       "1420070400000       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1420074000000       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1420077600000       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1420081200000       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1420084800000       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "               NPWD2872  NPWD2881  NPWD2882  \n",
       "ut_ms                                        \n",
       "1420070400000       0.0       0.0       0.0  \n",
       "1420074000000       0.0       0.0       0.0  \n",
       "1420077600000       0.0       0.0       0.0  \n",
       "1420081200000       0.0       0.0       0.0  \n",
       "1420084800000       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from tqdm import trange, tqdm\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (5, 5)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hackathon.utils.utils import *\n",
    "from hackathon.utils.draw_utils import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = parse_data(\"../data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sunmars_km',\n",
       " 'earthmars_km',\n",
       " 'sunmarsearthangle_deg',\n",
       " 'solarconstantmars',\n",
       " 'eclipseduration_min',\n",
       " 'occultationduration_min',\n",
       " 'sa',\n",
       " 'sx',\n",
       " 'sy',\n",
       " 'sz',\n",
       " 'dmop_count_24h_AAAA',\n",
       " 'dmop_count_24h_AACF',\n",
       " 'dmop_count_24h_ADMC',\n",
       " 'dmop_count_24h_AHHH',\n",
       " 'dmop_count_24h_AMMM',\n",
       " 'dmop_count_24h_AOOO',\n",
       " 'dmop_count_24h_APSF',\n",
       " 'dmop_count_24h_APWF',\n",
       " 'dmop_count_24h_ASEQ',\n",
       " 'dmop_count_24h_ASSS',\n",
       " 'dmop_count_24h_ASXX',\n",
       " 'dmop_count_24h_ATMB',\n",
       " 'dmop_count_24h_ATTT',\n",
       " 'dmop_count_24h_AVVV',\n",
       " 'dmop_count_24h_AXXX',\n",
       " 'dmop_count_24h_sum',\n",
       " 'flagcomms',\n",
       " 'EARTH',\n",
       " 'SLEW',\n",
       " 'NADIR',\n",
       " 'MAINTENANCE',\n",
       " 'INERTIAL',\n",
       " 'ACROSS_TRACK',\n",
       " 'WARMUP',\n",
       " 'D1PVMC',\n",
       " 'RADIO_SCIENCE',\n",
       " 'SPECULAR',\n",
       " 'D4PNPO',\n",
       " 'D3POCM',\n",
       " 'D2PLND',\n",
       " 'D5PPHB',\n",
       " 'D7PLTS',\n",
       " 'D8PLTP',\n",
       " 'SPOT',\n",
       " 'D9PSPO',\n",
       " 'usbx',\n",
       " 'usby',\n",
       " 'usbz']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_columns = filter(lambda x: \"NPWD\" not in x \n",
    "                   and 'ut_ms' not in x, test_data.columns)\n",
    "x_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NPWD2372',\n",
       " 'NPWD2401',\n",
       " 'NPWD2402',\n",
       " 'NPWD2451',\n",
       " 'NPWD2471',\n",
       " 'NPWD2472',\n",
       " 'NPWD2481',\n",
       " 'NPWD2482',\n",
       " 'NPWD2491',\n",
       " 'NPWD2501',\n",
       " 'NPWD2531',\n",
       " 'NPWD2532',\n",
       " 'NPWD2551',\n",
       " 'NPWD2552',\n",
       " 'NPWD2561',\n",
       " 'NPWD2562',\n",
       " 'NPWD2691',\n",
       " 'NPWD2692',\n",
       " 'NPWD2721',\n",
       " 'NPWD2722',\n",
       " 'NPWD2742',\n",
       " 'NPWD2771',\n",
       " 'NPWD2791',\n",
       " 'NPWD2792',\n",
       " 'NPWD2801',\n",
       " 'NPWD2802',\n",
       " 'NPWD2821',\n",
       " 'NPWD2851',\n",
       " 'NPWD2852',\n",
       " 'NPWD2871',\n",
       " 'NPWD2872',\n",
       " 'NPWD2881',\n",
       " 'NPWD2882']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_columns = filter(lambda x: \"NPWD\"  in x, test_data.columns)\n",
    "y_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = test_data[x_columns]\n",
    "X_test = X_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_5 = model_5.predict(X_test)\n",
    "\n",
    "predicts = pred_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = test_data[x_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(data=predicts, index=X_test.index, columns=y_columns)\n",
    "submission_df.index = to_utms(submission_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NPWD2372</th>\n",
       "      <th>NPWD2401</th>\n",
       "      <th>NPWD2402</th>\n",
       "      <th>NPWD2451</th>\n",
       "      <th>NPWD2471</th>\n",
       "      <th>NPWD2472</th>\n",
       "      <th>NPWD2481</th>\n",
       "      <th>NPWD2482</th>\n",
       "      <th>NPWD2491</th>\n",
       "      <th>NPWD2501</th>\n",
       "      <th>...</th>\n",
       "      <th>NPWD2792</th>\n",
       "      <th>NPWD2801</th>\n",
       "      <th>NPWD2802</th>\n",
       "      <th>NPWD2821</th>\n",
       "      <th>NPWD2851</th>\n",
       "      <th>NPWD2852</th>\n",
       "      <th>NPWD2871</th>\n",
       "      <th>NPWD2872</th>\n",
       "      <th>NPWD2881</th>\n",
       "      <th>NPWD2882</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ut_ms</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1420070400000</th>\n",
       "      <td>0.149290</td>\n",
       "      <td>-0.000430</td>\n",
       "      <td>0.175101</td>\n",
       "      <td>0.780960</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.221351</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.165690</td>\n",
       "      <td>0.005739</td>\n",
       "      <td>0.398400</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.033043</td>\n",
       "      <td>0.003651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420074000000</th>\n",
       "      <td>0.117741</td>\n",
       "      <td>0.002175</td>\n",
       "      <td>0.175200</td>\n",
       "      <td>0.578721</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>-0.001174</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.188289</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.073567</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>0.227190</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.025179</td>\n",
       "      <td>0.003511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420077600000</th>\n",
       "      <td>0.162978</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>0.175434</td>\n",
       "      <td>0.843790</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.007436</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.241261</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.190875</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>0.452123</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.032472</td>\n",
       "      <td>0.003943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420081200000</th>\n",
       "      <td>0.162978</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>0.175434</td>\n",
       "      <td>0.843790</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.007436</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>0.241261</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.190875</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>0.452123</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.032472</td>\n",
       "      <td>0.003943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420084800000</th>\n",
       "      <td>0.153190</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>0.175225</td>\n",
       "      <td>0.797116</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.003822</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.226430</td>\n",
       "      <td>0.005544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.172952</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>0.413435</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.033285</td>\n",
       "      <td>0.003730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               NPWD2372  NPWD2401  NPWD2402  NPWD2451  NPWD2471  NPWD2472  \\\n",
       "ut_ms                                                                       \n",
       "1420070400000  0.149290 -0.000430  0.175101  0.780960  0.000741  0.001296   \n",
       "1420074000000  0.117741  0.002175  0.175200  0.578721  0.000759  0.000808   \n",
       "1420077600000  0.162978  0.000858  0.175434  0.843790  0.001007  0.000775   \n",
       "1420081200000  0.162978  0.000858  0.175434  0.843790  0.001007  0.000775   \n",
       "1420084800000  0.153190 -0.000083  0.175225  0.797116  0.000811  0.001109   \n",
       "\n",
       "               NPWD2481  NPWD2482  NPWD2491  NPWD2501    ...     NPWD2792  \\\n",
       "ut_ms                                                    ...                \n",
       "1420070400000  0.002645  0.000248  0.221351  0.005444    ...     0.001339   \n",
       "1420074000000 -0.001174  0.002201  0.188289  0.005510    ...     0.000973   \n",
       "1420077600000  0.007436  0.001627  0.241261  0.005999    ...     0.001466   \n",
       "1420081200000  0.007436  0.001627  0.241261  0.005999    ...     0.001466   \n",
       "1420084800000  0.003822  0.000641  0.226430  0.005544    ...     0.001396   \n",
       "\n",
       "               NPWD2801  NPWD2802  NPWD2821  NPWD2851  NPWD2852  NPWD2871  \\\n",
       "ut_ms                                                                       \n",
       "1420070400000  0.001403  0.165690  0.005739  0.398400  0.000133  0.000648   \n",
       "1420074000000  0.001596  0.073567  0.005750  0.227190 -0.000092  0.001009   \n",
       "1420077600000  0.001432  0.190875  0.005365  0.452123 -0.000393  0.001003   \n",
       "1420081200000  0.001432  0.190875  0.005365  0.452123 -0.000393  0.001003   \n",
       "1420084800000  0.001369  0.172952  0.005633  0.413435 -0.000049  0.000745   \n",
       "\n",
       "               NPWD2872  NPWD2881  NPWD2882  \n",
       "ut_ms                                        \n",
       "1420070400000  0.000688  0.033043  0.003651  \n",
       "1420074000000  0.000776  0.025179  0.003511  \n",
       "1420077600000  0.000813  0.032472  0.003943  \n",
       "1420081200000  0.000813  0.032472  0.003943  \n",
       "1420084800000  0.000714  0.033285  0.003730  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('../data/hackathon/nitinol_sub4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
